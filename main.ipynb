{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "227a1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33803a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {} #Make dictionary for all values\n",
    "data['landmarks_vectorised'] = [] #assign a key value to record landmarks\n",
    "emotions = [\"colere\", \"degout\", \"peur\", \"joie\", \"tristesse\", \"surprise\"] #Emotion list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6531d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_landmarks(image):\n",
    "    detections = detector(image, 1)\n",
    "    for k,d in enumerate(detections): #For all detected face instances individually\n",
    "        shape = predictor(image, d) #Draw Facial Landmarks with the predictor class\n",
    "        xlist = []\n",
    "        ylist = []\n",
    "        for i in range(1,68): #Store X and Y coordinates in two lists\n",
    "            xlist.append(float(shape.part(i).x))\n",
    "            ylist.append(float(shape.part(i).y))\n",
    "        #record mean values of both X Y coordinates    \n",
    "        xmean = np.mean(xlist)\n",
    "        ymean = np.mean(ylist)\n",
    "        #store central deviance \n",
    "        xcentral = [(x-xmean) for x in xlist]\n",
    "        ycentral = [(y-ymean) for y in ylist]\n",
    "\n",
    "        landmarks_vectorised = []\n",
    "        for x, y, w, z in zip(xcentral, ycentral, xlist, ylist):#analysing presence of facial landmarks \n",
    "            landmarks_vectorised.append(w)\n",
    "            landmarks_vectorised.append(z)\n",
    "            #extract center of gravity with mean of axis\n",
    "            meannp = np.asarray((ymean,xmean))\n",
    "            coornp = np.asarray((z,w))\n",
    "            #measuring distance and angle of each landmark from center of gravity \n",
    "            dist = np.linalg.norm(coornp-meannp)\n",
    "            landmarks_vectorised.append(dist)\n",
    "            landmarks_vectorised.append((math.atan2(y, x)*360)/(2*math.pi))\n",
    "        \n",
    "        data['landmarks_vectorised'] = landmarks_vectorised#store landmarks in global dictionary \n",
    "    if len(detections) < 1: #if no landmarks were detected, store error in dictionary \n",
    "        data['landmarks_vestorised'] = \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2851de3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.svm.classes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18356\\771236206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpkl_filename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'pickle_model.pkl'\u001b[0m \u001b[1;31m#trained model file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_filename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m#load all weights from model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpickle_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mvideo_capture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Capture Webcam object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Face detector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.svm.classes'"
     ]
    }
   ],
   "source": [
    "#Set up some required objects\n",
    "pkl_filename = 'pickle_model.pkl' #trained model file \n",
    "with open(pkl_filename, 'rb') as file:  #load all weights from model \n",
    "    pickle_model = pickle.load(file) \n",
    "video_capture = cv2.VideoCapture(0) #Capture Webcam object\n",
    "detector = dlib.get_frontal_face_detector() #Face detector\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\") #Landmark identifier.\n",
    "FACE_SHAPE = (200, 200) #Size of capture frame - reAdjustable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dc39b0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_capture' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20580\\3027981609.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#store input feed in frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Display the webcam output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFACE_SHAPE\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#resized frame to smaller size to do faster processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#convert to grayscale as our dataset was grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_capture' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    ret, frame = video_capture.read() #store input feed in frame\n",
    "    cv2.imshow(\"image\", frame) #Display the webcam output\n",
    "    frame = cv2.resize(frame, FACE_SHAPE)  #resized frame to smaller size to do faster processing \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) #convert to grayscale as our dataset was grayscale\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)) #Does Local adapative histogram equalization for improved feed \n",
    "    clahe_image = clahe.apply(gray) #applies LAHE \n",
    "    get_landmarks(clahe_image) #obtain landmarks from input feed \n",
    "\n",
    "    if data['landmarks_vectorised'] != \"error\": #if landmarks are detected..\n",
    "        prediction_data = np.array(data['landmarks_vectorised']) #convert to numpy array ..\n",
    "        predicted_labels = pickle_model.predict(prediction_data.reshape(1,-1)) #to get predicted values ...\n",
    "        print (emotions[predicted_labels[0]]) #prints the predicted emotion   \n",
    "    else:\n",
    "         print(\"no face detected on this one\") \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #Exit program when the user presses 'q'\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
